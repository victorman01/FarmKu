{"cells":[{"cell_type":"markdown","metadata":{"id":"7ouauFjMgxG6"},"source":["# Library"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"-K9CTJC7g1rW","executionInfo":{"status":"ok","timestamp":1684987779835,"user_tz":-420,"elapsed":8851,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"outputs":[],"source":["import os\n","import shutil\n","import zipfile\n","import random\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{"id":"W1rvPOX0bv8q"},"source":["# Data"]},{"cell_type":"code","source":["source_dir = '/Users/bened/Python/Farmku/Rice/LabelledRice'\n","\n","# Image path\n","image_dir = os.path.join(source_dir, 'Labelled')\n","\n","# Training\n","training_path = os.path.join(source_dir, 'training')\n","brownspot_training_path = os.path.join(training_path, 'BrownSpot')\n","healthy_training_path = os.path.join(training_path, 'Healthy')\n","hispa_training_path = os.path.join(training_path, 'Hispa')\n","leafblast_training_path = os.path.join(training_path, 'LeafBlast')\n","\n","if not os.path.isdir(training_path):\n","  os.makedirs(training_path)\n","if not os.path.isdir(brownspot_training_path):\n","  os.makedirs(brownspot_training_path)\n","if not os.path.isdir(healthy_training_path):\n","  os.makedirs(healthy_training_path)\n","if not os.path.isdir(hispa_training_path):\n","  os.makedirs(hispa_training_path)\n","if not os.path.isdir(leafblast_training_path):\n","  os.makedirs(leafblast_training_path)\n","\n","# Validation\n","validation_path = os.path.join(source_dir, 'validation')\n","brownspot_validation_path = os.path.join(validation_path, 'BrownSpot')\n","healthy_validation_path = os.path.join(validation_path, 'Healthy')\n","hispa_validation_path = os.path.join(validation_path, 'Hispa')\n","leafblast_validation_path = os.path.join(validation_path, 'LeafBlast')\n","\n","\n","if not os.path.isdir(validation_path):\n","  os.makedirs(validation_path)\n","if not os.path.isdir(brownspot_validation_path):\n","  os.makedirs(brownspot_validation_path)\n","if not os.path.isdir(healthy_validation_path):\n","  os.makedirs(healthy_validation_path)\n","if not os.path.isdir(hispa_validation_path):\n","  os.makedirs(hispa_validation_path)\n","if not os.path.isdir(leafblast_validation_path):\n","  os.makedirs(leafblast_validation_path)\n","\n","# Testing\n","testing_path = os.path.join(source_dir, 'testing')\n","brownspot_testing_path = os.path.join(testing_path, 'BrownSpot')\n","healthy_testing_path = os.path.join(testing_path, 'Healthy')\n","hispa_testing_path = os.path.join(testing_path, 'Hispa')\n","leafblast_testing_path = os.path.join(testing_path, 'LeafBlast')\n","\n","if not os.path.isdir(testing_path):\n","  os.makedirs(testing_path)\n","if not os.path.isdir(brownspot_testing_path):\n","  os.makedirs(brownspot_testing_path)\n","if not os.path.isdir(healthy_testing_path):\n","  os.makedirs(healthy_testing_path)\n","if not os.path.isdir(hispa_testing_path):\n","  os.makedirs(hispa_testing_path)\n","if not os.path.isdir(leafblast_testing_path):\n","  os.makedirs(leafblast_testing_path)"],"metadata":{"id":"QvYdDzYRlHZH","executionInfo":{"status":"ok","timestamp":1684987781650,"user_tz":-420,"elapsed":33,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XW3BnW6jko0S"},"source":["# Dont Run This"]},{"cell_type":"code","source":["diseases = ['BrownSpot', 'Healthy', 'Hispa', 'LeafBlast']\n","num_image_disease = [len(os.listdir(os.path.join(image_dir, x))) for x in diseases]\n","num_image_disease"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFuqT-0_qNkU","executionInfo":{"status":"ok","timestamp":1684987784522,"user_tz":-420,"elapsed":17,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}},"outputId":"592b2948-4558-4775-b33d-11cc125237e6"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[523, 1488, 565, 779]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["for disease in diseases:\n","  disease_path = os.path.join(image_dir, disease)\n","  image_list = os.listdir(disease_path)\n","  shuffle_image_list = random.sample(image_list, len(image_list))\n","  if len(image_list) > 1000:\n","    remove_list = shuffle_image_list[1000:]\n","    for image in remove_list:\n","      image_path = os.path.join(disease_path, image)\n","      os.remove(image_path)\n","  else:\n","    n_new = 1000 - len(image_list)\n","    add_list = shuffle_image_list[:n_new]\n","    for image in add_list:\n","      image_path = os.path.join(disease_path, image)\n","      image_name = image + '_1.jpg'\n","      new_image_path = os.path.join(disease_path, image_name)\n","      shutil.copy(image_path, new_image_path)"],"metadata":{"id":"zXdn0qr54iBD","executionInfo":{"status":"ok","timestamp":1684987812085,"user_tz":-420,"elapsed":26021,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["num_image_disease = [len(os.listdir(os.path.join(image_dir, x))) for x in diseases]\n","num_image_disease"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXU2nO39DT5d","executionInfo":{"status":"ok","timestamp":1684987815148,"user_tz":-420,"elapsed":57,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}},"outputId":"dba0e8cd-0320-4da7-a558-9a364643ebd9"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1000, 1000, 1000, 1000]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uhP6IRBYkv8N","executionInfo":{"status":"ok","timestamp":1684987820160,"user_tz":-420,"elapsed":2026,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"outputs":[],"source":["train_size = 0.8\n","for disease in diseases:\n","  data_path = os.path.join(image_dir, disease)\n","  data = os.listdir(data_path)\n","  shuffle = random.sample(data, len(data))\n","\n","  n_train = math.ceil(len(shuffle) * train_size)\n","  n_val = math.ceil(len(shuffle) * (1-train_size) / 2)\n","  n_test = len(shuffle) - n_train - n_val\n","\n","  train_list = shuffle[:n_train]\n","  validation_list = shuffle[n_train:(n_train + n_val)]\n","  test_list = shuffle[(n_train + n_val):(n_train + n_val + n_test)]\n","\n","  move_training_path = os.path.join(training_path, disease)\n","  move_validation_path = os.path.join(validation_path, disease)\n","  move_testing_path = os.path.join(testing_path, disease)\n","\n","  for image_name in train_list:\n","    image_path = os.path.join(data_path, image_name)\n","    shutil.move(image_path, move_training_path)\n","  for image_name in validation_list:\n","    image_path = os.path.join(data_path, image_name)\n","    shutil.move(image_path, move_validation_path)\n","  for image_name in test_list:\n","    image_path = os.path.join(data_path, image_name)\n","    shutil.move(image_path, move_testing_path)"]},{"cell_type":"markdown","source":["# Next"],"metadata":{"id":"EW4dnctEExx2"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ti3nhKSBixyO","executionInfo":{"status":"ok","timestamp":1684987825253,"user_tz":-420,"elapsed":19,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}},"outputId":"d4fb3e6f-008c-490c-af3f-cb8d85585566"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of BrownSpot data: \n"," Training data: 800 \n"," Validation data: 100 \n"," Testing data: 100 \n","\n","Number of Healthy data: \n"," Training data: 800 \n"," Validation data: 100 \n"," Testing data: 100 \n","\n","Number of Hispa data: \n"," Training data: 800 \n"," Validation data: 100 \n"," Testing data: 100 \n","\n","Number of LeafBlast data: \n"," Training data: 800 \n"," Validation data: 100 \n"," Testing data: 100 \n","\n"]}],"source":["# Number of training, validation, and testing\n","print(f'Number of BrownSpot data: \\n Training data: {len(os.listdir(brownspot_training_path))} \\n Validation data: {len(os.listdir(brownspot_validation_path))} \\n Testing data: {len(os.listdir(brownspot_testing_path))} \\n')\n","print(f'Number of Healthy data: \\n Training data: {len(os.listdir(healthy_training_path))} \\n Validation data: {len(os.listdir(healthy_validation_path))} \\n Testing data: {len(os.listdir(healthy_testing_path))} \\n')\n","print(f'Number of Hispa data: \\n Training data: {len(os.listdir(hispa_training_path))} \\n Validation data: {len(os.listdir(hispa_validation_path))} \\n Testing data: {len(os.listdir(hispa_testing_path))} \\n')\n","print(f'Number of LeafBlast data: \\n Training data: {len(os.listdir(leafblast_training_path))} \\n Validation data: {len(os.listdir(leafblast_validation_path))} \\n Testing data: {len(os.listdir(leafblast_testing_path))} \\n')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-2_S1X0xndf","executionInfo":{"status":"ok","timestamp":1684987832354,"user_tz":-420,"elapsed":209,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}},"outputId":"24a12de3-8c2b-4574-f758-001d784f01e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3200 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n"]}],"source":["img_size = (224, 224)\n","\n","training_datagen = ImageDataGenerator(rescale=1/255,\n","                                      rotation_range = 40,\n","                                      width_shift_range = 0.2,\n","                                      height_shift_range = 0.2,\n","                                      shear_range = 0.2,\n","                                      zoom_range = 0.2,\n","                                      horizontal_flip = True)\n","validation_datagen = ImageDataGenerator(rescale=1/255)\n","testing_datagen = ImageDataGenerator(rescale=1/255)\n","\n","training_dataset = training_datagen.flow_from_directory(training_path,\n","                                                          shuffle=True,\n","                                                          batch_size=64,\n","                                                          class_mode='categorical',\n","                                                          target_size=img_size)\n","validation_dataset = validation_datagen.flow_from_directory(validation_path,\n","                                                            shuffle=True,\n","                                                            batch_size=32,\n","                                                            class_mode='categorical',\n","                                                            target_size=img_size)\n","testing_dataset = testing_datagen.flow_from_directory(testing_path,\n","                                                      shuffle=True,\n","                                                      batch_size=32,\n","                                                      class_mode='categorical',\n","                                                      target_size=img_size)"]},{"cell_type":"markdown","metadata":{"id":"Td1os28AzztT"},"source":["# Model"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"fy39m3bWz1k0","executionInfo":{"status":"ok","timestamp":1684987880053,"user_tz":-420,"elapsed":2725,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"outputs":[],"source":["img_shape = img_size + (3,)\n","base_model = tf.keras.applications.InceptionV3(input_shape=img_shape,\n","                                               include_top=False,\n","                                               weights='imagenet')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2330,"status":"ok","timestamp":1684987883726,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"},"user_tz":-420},"id":"US6nGHnO0yio","outputId":"f9cfb845-a6c4-4817-9c48-cd7c86b1758d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"inception_v3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n"," alization)                     )                                                                 \n","                                                                                                  \n"," activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n"," ing2D)                                                                                           \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n","                                                                  'activation_7[0][0]',           \n","                                                                  'activation_10[0][0]',          \n","                                                                  'activation_11[0][0]']          \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n","                                                                  'activation_14[0][0]',          \n","                                                                  'activation_17[0][0]',          \n","                                                                  'activation_18[0][0]']          \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n","                                                                  'activation_21[0][0]',          \n","                                                                  'activation_24[0][0]',          \n","                                                                  'activation_25[0][0]']          \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n","                                                                                                  \n"," mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n","                                                                  'activation_29[0][0]',          \n","                                                                  'max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n","                                                                                                  \n"," activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n","                                                                                                  \n"," mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n","                                                                  'activation_33[0][0]',          \n","                                                                  'activation_38[0][0]',          \n","                                                                  'activation_39[0][0]']          \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n","                                                                                                  \n"," activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n","                                                                                                  \n"," activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n","                                                                  'activation_43[0][0]',          \n","                                                                  'activation_48[0][0]',          \n","                                                                  'activation_49[0][0]']          \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n","                                                                                                  \n"," activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n","                                                                                                  \n"," average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n","                                                                  'activation_53[0][0]',          \n","                                                                  'activation_58[0][0]',          \n","                                                                  'activation_59[0][0]']          \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n","                                                                                                  \n"," conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n","                                                                                                  \n"," conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n","                                                                                                  \n"," activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n","                                                                                                  \n"," activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n","                                                                                                  \n"," mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n","                                                                  'activation_63[0][0]',          \n","                                                                  'activation_68[0][0]',          \n","                                                                  'activation_69[0][0]']          \n","                                                                                                  \n"," conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n","                                                                                                  \n"," conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n","                                                                                                  \n"," conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n","                                                                                                  \n"," conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n","                                                                                                  \n"," mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n","                                                                  'activation_75[0][0]',          \n","                                                                  'max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n","                                                                                                  \n"," conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n","                                                                                                  \n"," conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n","                                                                                                  \n"," conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n","                                                                                                  \n"," conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n","                                                                                                  \n"," conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n","                                                                                                  \n"," average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n","                                                                                                  \n"," activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n","                                                                  'activation_79[0][0]']          \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n","                                                                  'activation_83[0][0]']          \n","                                                                                                  \n"," activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n","                                                                                                  \n"," mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n","                                                                  'mixed9_0[0][0]',               \n","                                                                  'concatenate[0][0]',            \n","                                                                  'activation_84[0][0]']          \n","                                                                                                  \n"," conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n","                                                                                                  \n"," conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n","                                                                                                  \n"," conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n","                                                                                                  \n"," conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n","                                                                                                  \n"," conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n","                                                                                                  \n"," conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n","                                                                                                  \n"," average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n","                                                                                                  \n"," activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n","                                                                  'activation_88[0][0]']          \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n","                                                                  'activation_92[0][0]']          \n","                                                                                                  \n"," activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n","                                                                                                  \n"," mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n","                                                                  'mixed9_1[0][0]',               \n","                                                                  'concatenate_1[0][0]',          \n","                                                                  'activation_93[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 21,802,784\n","Trainable params: 0\n","Non-trainable params: 21,802,784\n","__________________________________________________________________________________________________\n"]}],"source":["for layer in base_model.layers:\n","  layer.trainable = False\n","base_model.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"W2gGexQt1nUF","executionInfo":{"status":"ok","timestamp":1684987931452,"user_tz":-420,"elapsed":12,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"outputs":[],"source":["def custom_model_2(last_layer = base_model.output):\n","  x = tf.keras.layers.Flatten()(last_layer)\n","  x = tf.keras.layers.Dense(128, activation='relu')(x)\n","  x = tf.keras.layers.BatchNormalization()(x)\n","  x = tf.keras.layers.Dropout(0.2)(x)\n","  x = tf.keras.layers.Dense(4, activation='softmax')(x)\n","\n","  model = tf.keras.Model(inputs=base_model.input, outputs=x)\n","\n","  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","  return model"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2475,"status":"ok","timestamp":1684987938797,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"},"user_tz":-420},"id":"UEuZdTp73hkM","outputId":"b16c60ea-92a2-490e-db6d-05673502196a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n"," alization)                     )                                                                 \n","                                                                                                  \n"," activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n"," ing2D)                                                                                           \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n","                                                                  'activation_7[0][0]',           \n","                                                                  'activation_10[0][0]',          \n","                                                                  'activation_11[0][0]']          \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n","                                                                  'activation_14[0][0]',          \n","                                                                  'activation_17[0][0]',          \n","                                                                  'activation_18[0][0]']          \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n","                                                                  'activation_21[0][0]',          \n","                                                                  'activation_24[0][0]',          \n","                                                                  'activation_25[0][0]']          \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n","                                                                                                  \n"," mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n","                                                                  'activation_29[0][0]',          \n","                                                                  'max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n","                                                                                                  \n"," activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n","                                                                                                  \n"," mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n","                                                                  'activation_33[0][0]',          \n","                                                                  'activation_38[0][0]',          \n","                                                                  'activation_39[0][0]']          \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n","                                                                                                  \n"," activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n","                                                                                                  \n"," activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n","                                                                  'activation_43[0][0]',          \n","                                                                  'activation_48[0][0]',          \n","                                                                  'activation_49[0][0]']          \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n","                                                                                                  \n"," activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n","                                                                                                  \n"," average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n","                                                                  'activation_53[0][0]',          \n","                                                                  'activation_58[0][0]',          \n","                                                                  'activation_59[0][0]']          \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n","                                                                                                  \n"," conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n","                                                                                                  \n"," conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n","                                                                                                  \n"," activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n","                                                                                                  \n"," activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n","                                                                                                  \n"," mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n","                                                                  'activation_63[0][0]',          \n","                                                                  'activation_68[0][0]',          \n","                                                                  'activation_69[0][0]']          \n","                                                                                                  \n"," conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n","                                                                                                  \n"," conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n","                                                                                                  \n"," conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n","                                                                                                  \n"," conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n","                                                                                                  \n"," mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n","                                                                  'activation_75[0][0]',          \n","                                                                  'max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n","                                                                                                  \n"," conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n","                                                                                                  \n"," conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n","                                                                                                  \n"," conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n","                                                                                                  \n"," conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n","                                                                                                  \n"," conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n","                                                                                                  \n"," average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n","                                                                                                  \n"," activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n","                                                                  'activation_79[0][0]']          \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n","                                                                  'activation_83[0][0]']          \n","                                                                                                  \n"," activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n","                                                                                                  \n"," mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n","                                                                  'mixed9_0[0][0]',               \n","                                                                  'concatenate[0][0]',            \n","                                                                  'activation_84[0][0]']          \n","                                                                                                  \n"," conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n","                                                                                                  \n"," conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n","                                                                                                  \n"," conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n","                                                                                                  \n"," conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n","                                                                                                  \n"," conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n","                                                                                                  \n"," conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n","                                                                                                  \n"," average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n","                                                                                                  \n"," activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n","                                                                  'activation_88[0][0]']          \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n","                                                                  'activation_92[0][0]']          \n","                                                                                                  \n"," activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n","                                                                                                  \n"," mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n","                                                                  'mixed9_1[0][0]',               \n","                                                                  'concatenate_1[0][0]',          \n","                                                                  'activation_93[0][0]']          \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 51200)        0           ['mixed10[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, 128)          6553728     ['flatten_1[0][0]']              \n","                                                                                                  \n"," batch_normalization_95 (BatchN  (None, 128)         512         ['dense_2[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 128)          0           ['batch_normalization_95[0][0]'] \n","                                                                                                  \n"," dense_3 (Dense)                (None, 4)            516         ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 28,357,540\n","Trainable params: 6,554,500\n","Non-trainable params: 21,803,040\n","__________________________________________________________________________________________________\n"]}],"source":["custom_model_2 = custom_model_2()\n","custom_model_2.summary()"]},{"cell_type":"code","source":["acc_ckp_path = '/Users/bened/Python/Farmku/Rice/acc_best_model_2.hdf5'\n","acc_checkpoint = tf.keras.callbacks.ModelCheckpoint(acc_ckp_path, monitor='accuracy', verbose=2,\n","    save_best_only=True, mode='auto', save_freq='epoch')\n","\n","val_acc_ckp_path = '/Users/bened/Python/Farmku/Rice/val_acc_best_model_2.hdf5'\n","val_acc_checkpoint = tf.keras.callbacks.ModelCheckpoint(val_acc_ckp_path, monitor='val_accuracy', verbose=2,\n","    save_best_only=True, mode='auto', save_freq='epoch')\n","\n","class stopEpoch(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy') >= 0.95 or (logs.get('accuracy') > 0.92 and logs.get('val_accuracy') > 0.90)):\n","      print(\"\\nThreshold achieve!\\n\")\n","      self.model.stop_training = True"],"metadata":{"id":"zQjno9Cg-cPx","executionInfo":{"status":"ok","timestamp":1684988006904,"user_tz":-420,"elapsed":15,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hgklgIa36Qc","outputId":"e4f6dc48-87c9-4cb7-bbaf-8d6e56d9db0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","50/50 [==============================] - ETA: 0s - loss: 1.5071 - accuracy: 0.4437\n","Epoch 1: accuracy improved from -inf to 0.44375, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 1: val_accuracy improved from -inf to 0.45750, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 370s 7s/step - loss: 1.5071 - accuracy: 0.4437 - val_loss: 1.7302 - val_accuracy: 0.4575\n","Epoch 2/200\n","50/50 [==============================] - ETA: 0s - loss: 1.2193 - accuracy: 0.5041\n","Epoch 2: accuracy improved from 0.44375 to 0.50406, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 2: val_accuracy improved from 0.45750 to 0.55750, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 344s 7s/step - loss: 1.2193 - accuracy: 0.5041 - val_loss: 1.1506 - val_accuracy: 0.5575\n","Epoch 3/200\n","50/50 [==============================] - ETA: 0s - loss: 1.1242 - accuracy: 0.5341\n","Epoch 3: accuracy improved from 0.50406 to 0.53406, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 3: val_accuracy did not improve from 0.55750\n","50/50 [==============================] - 350s 7s/step - loss: 1.1242 - accuracy: 0.5341 - val_loss: 1.2811 - val_accuracy: 0.5125\n","Epoch 4/200\n","50/50 [==============================] - ETA: 0s - loss: 1.1079 - accuracy: 0.5484\n","Epoch 4: accuracy improved from 0.53406 to 0.54844, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 4: val_accuracy improved from 0.55750 to 0.59500, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 355s 7s/step - loss: 1.1079 - accuracy: 0.5484 - val_loss: 1.0449 - val_accuracy: 0.5950\n","Epoch 5/200\n","50/50 [==============================] - ETA: 0s - loss: 1.1106 - accuracy: 0.5369\n","Epoch 5: accuracy did not improve from 0.54844\n","\n","Epoch 5: val_accuracy did not improve from 0.59500\n","50/50 [==============================] - 352s 7s/step - loss: 1.1106 - accuracy: 0.5369 - val_loss: 1.1106 - val_accuracy: 0.5625\n","Epoch 6/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0839 - accuracy: 0.5491\n","Epoch 6: accuracy improved from 0.54844 to 0.54906, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 6: val_accuracy did not improve from 0.59500\n","50/50 [==============================] - 363s 7s/step - loss: 1.0839 - accuracy: 0.5491 - val_loss: 1.0069 - val_accuracy: 0.5625\n","Epoch 7/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.5681\n","Epoch 7: accuracy improved from 0.54906 to 0.56813, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 7: val_accuracy did not improve from 0.59500\n","50/50 [==============================] - 356s 7s/step - loss: 1.0431 - accuracy: 0.5681 - val_loss: 1.0238 - val_accuracy: 0.5775\n","Epoch 8/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0356 - accuracy: 0.5650\n","Epoch 8: accuracy did not improve from 0.56813\n","\n","Epoch 8: val_accuracy improved from 0.59500 to 0.60250, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 356s 7s/step - loss: 1.0356 - accuracy: 0.5650 - val_loss: 1.0039 - val_accuracy: 0.6025\n","Epoch 9/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0276 - accuracy: 0.5713\n","Epoch 9: accuracy improved from 0.56813 to 0.57125, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 9: val_accuracy did not improve from 0.60250\n","50/50 [==============================] - 357s 7s/step - loss: 1.0276 - accuracy: 0.5713 - val_loss: 1.0763 - val_accuracy: 0.5500\n","Epoch 10/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.5800\n","Epoch 10: accuracy improved from 0.57125 to 0.58000, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 10: val_accuracy did not improve from 0.60250\n","50/50 [==============================] - 368s 7s/step - loss: 1.0062 - accuracy: 0.5800 - val_loss: 0.9906 - val_accuracy: 0.5700\n","Epoch 11/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0142 - accuracy: 0.5825\n","Epoch 11: accuracy improved from 0.58000 to 0.58250, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 11: val_accuracy did not improve from 0.60250\n","50/50 [==============================] - 384s 8s/step - loss: 1.0142 - accuracy: 0.5825 - val_loss: 1.0583 - val_accuracy: 0.5875\n","Epoch 12/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.5872\n","Epoch 12: accuracy improved from 0.58250 to 0.58719, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 12: val_accuracy did not improve from 0.60250\n","50/50 [==============================] - 364s 7s/step - loss: 1.0174 - accuracy: 0.5872 - val_loss: 0.9937 - val_accuracy: 0.6025\n","Epoch 13/200\n","50/50 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.5866\n","Epoch 13: accuracy did not improve from 0.58719\n","\n","Epoch 13: val_accuracy did not improve from 0.60250\n","50/50 [==============================] - 360s 7s/step - loss: 1.0024 - accuracy: 0.5866 - val_loss: 0.9779 - val_accuracy: 0.5950\n","Epoch 14/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9895 - accuracy: 0.5881\n","Epoch 14: accuracy improved from 0.58719 to 0.58812, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 14: val_accuracy did not improve from 0.60250\n","50/50 [==============================] - 362s 7s/step - loss: 0.9895 - accuracy: 0.5881 - val_loss: 1.0438 - val_accuracy: 0.5775\n","Epoch 15/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9856 - accuracy: 0.5816\n","Epoch 15: accuracy did not improve from 0.58812\n","\n","Epoch 15: val_accuracy improved from 0.60250 to 0.63250, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 365s 7s/step - loss: 0.9856 - accuracy: 0.5816 - val_loss: 1.0158 - val_accuracy: 0.6325\n","Epoch 16/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.6028\n","Epoch 16: accuracy improved from 0.58812 to 0.60281, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 16: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 362s 7s/step - loss: 0.9609 - accuracy: 0.6028 - val_loss: 0.9916 - val_accuracy: 0.6175\n","Epoch 17/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.5953\n","Epoch 17: accuracy did not improve from 0.60281\n","\n","Epoch 17: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 363s 7s/step - loss: 0.9642 - accuracy: 0.5953 - val_loss: 0.9933 - val_accuracy: 0.5925\n","Epoch 18/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9872 - accuracy: 0.5997\n","Epoch 18: accuracy did not improve from 0.60281\n","\n","Epoch 18: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 361s 7s/step - loss: 0.9872 - accuracy: 0.5997 - val_loss: 0.9816 - val_accuracy: 0.6250\n","Epoch 19/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9459 - accuracy: 0.6069\n","Epoch 19: accuracy improved from 0.60281 to 0.60688, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 19: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 360s 7s/step - loss: 0.9459 - accuracy: 0.6069 - val_loss: 1.0104 - val_accuracy: 0.5750\n","Epoch 20/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9377 - accuracy: 0.6172\n","Epoch 20: accuracy improved from 0.60688 to 0.61719, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 20: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 356s 7s/step - loss: 0.9377 - accuracy: 0.6172 - val_loss: 0.9832 - val_accuracy: 0.6125\n","Epoch 21/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.6047\n","Epoch 21: accuracy did not improve from 0.61719\n","\n","Epoch 21: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9368 - accuracy: 0.6047 - val_loss: 0.9893 - val_accuracy: 0.6075\n","Epoch 22/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9274 - accuracy: 0.6162\n","Epoch 22: accuracy did not improve from 0.61719\n","\n","Epoch 22: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9274 - accuracy: 0.6162 - val_loss: 0.9809 - val_accuracy: 0.6225\n","Epoch 23/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9459 - accuracy: 0.6056\n","Epoch 23: accuracy did not improve from 0.61719\n","\n","Epoch 23: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9459 - accuracy: 0.6056 - val_loss: 1.0113 - val_accuracy: 0.5900\n","Epoch 24/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9357 - accuracy: 0.6050\n","Epoch 24: accuracy did not improve from 0.61719\n","\n","Epoch 24: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9357 - accuracy: 0.6050 - val_loss: 0.9680 - val_accuracy: 0.6175\n","Epoch 25/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.6141\n","Epoch 25: accuracy did not improve from 0.61719\n","\n","Epoch 25: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9311 - accuracy: 0.6141 - val_loss: 0.9634 - val_accuracy: 0.6325\n","Epoch 26/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9346 - accuracy: 0.6100\n","Epoch 26: accuracy did not improve from 0.61719\n","\n","Epoch 26: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 356s 7s/step - loss: 0.9346 - accuracy: 0.6100 - val_loss: 1.0058 - val_accuracy: 0.6100\n","Epoch 27/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.6234\n","Epoch 27: accuracy improved from 0.61719 to 0.62344, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 27: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 360s 7s/step - loss: 0.9066 - accuracy: 0.6234 - val_loss: 0.9847 - val_accuracy: 0.6150\n","Epoch 28/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8983 - accuracy: 0.6225\n","Epoch 28: accuracy did not improve from 0.62344\n","\n","Epoch 28: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8983 - accuracy: 0.6225 - val_loss: 0.9838 - val_accuracy: 0.5850\n","Epoch 29/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.6206\n","Epoch 29: accuracy did not improve from 0.62344\n","\n","Epoch 29: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 358s 7s/step - loss: 0.9080 - accuracy: 0.6206 - val_loss: 0.9789 - val_accuracy: 0.6200\n","Epoch 30/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9002 - accuracy: 0.6212\n","Epoch 30: accuracy did not improve from 0.62344\n","\n","Epoch 30: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9002 - accuracy: 0.6212 - val_loss: 0.9387 - val_accuracy: 0.6125\n","Epoch 31/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9064 - accuracy: 0.6231\n","Epoch 31: accuracy did not improve from 0.62344\n","\n","Epoch 31: val_accuracy did not improve from 0.63250\n","50/50 [==============================] - 357s 7s/step - loss: 0.9064 - accuracy: 0.6231 - val_loss: 0.9197 - val_accuracy: 0.6225\n","Epoch 32/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.6309\n","Epoch 32: accuracy improved from 0.62344 to 0.63094, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 32: val_accuracy improved from 0.63250 to 0.64500, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 363s 7s/step - loss: 0.9057 - accuracy: 0.6309 - val_loss: 0.9590 - val_accuracy: 0.6450\n","Epoch 33/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.6181\n","Epoch 33: accuracy did not improve from 0.63094\n","\n","Epoch 33: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 360s 7s/step - loss: 0.9092 - accuracy: 0.6181 - val_loss: 0.9919 - val_accuracy: 0.5950\n","Epoch 34/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9083 - accuracy: 0.6137\n","Epoch 34: accuracy did not improve from 0.63094\n","\n","Epoch 34: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 359s 7s/step - loss: 0.9083 - accuracy: 0.6137 - val_loss: 0.9989 - val_accuracy: 0.5725\n","Epoch 35/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8892 - accuracy: 0.6225\n","Epoch 35: accuracy did not improve from 0.63094\n","\n","Epoch 35: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8892 - accuracy: 0.6225 - val_loss: 0.9158 - val_accuracy: 0.6150\n","Epoch 36/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9026 - accuracy: 0.6291\n","Epoch 36: accuracy did not improve from 0.63094\n","\n","Epoch 36: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 363s 7s/step - loss: 0.9026 - accuracy: 0.6291 - val_loss: 0.9888 - val_accuracy: 0.5850\n","Epoch 37/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6366\n","Epoch 37: accuracy improved from 0.63094 to 0.63656, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 37: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 362s 7s/step - loss: 0.8944 - accuracy: 0.6366 - val_loss: 0.9328 - val_accuracy: 0.6300\n","Epoch 38/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8780 - accuracy: 0.6353\n","Epoch 38: accuracy did not improve from 0.63656\n","\n","Epoch 38: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 359s 7s/step - loss: 0.8780 - accuracy: 0.6353 - val_loss: 0.9369 - val_accuracy: 0.6125\n","Epoch 39/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.6216\n","Epoch 39: accuracy did not improve from 0.63656\n","\n","Epoch 39: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 360s 7s/step - loss: 0.8838 - accuracy: 0.6216 - val_loss: 0.9483 - val_accuracy: 0.6400\n","Epoch 40/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8636 - accuracy: 0.6488\n","Epoch 40: accuracy improved from 0.63656 to 0.64875, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 40: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 359s 7s/step - loss: 0.8636 - accuracy: 0.6488 - val_loss: 0.9398 - val_accuracy: 0.6200\n","Epoch 41/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8792 - accuracy: 0.6375\n","Epoch 41: accuracy did not improve from 0.64875\n","\n","Epoch 41: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8792 - accuracy: 0.6375 - val_loss: 0.9709 - val_accuracy: 0.5850\n","Epoch 42/200\n","50/50 [==============================] - ETA: 0s - loss: 0.9027 - accuracy: 0.6291\n","Epoch 42: accuracy did not improve from 0.64875\n","\n","Epoch 42: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.9027 - accuracy: 0.6291 - val_loss: 0.9429 - val_accuracy: 0.6175\n","Epoch 43/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.6431\n","Epoch 43: accuracy did not improve from 0.64875\n","\n","Epoch 43: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 362s 7s/step - loss: 0.8853 - accuracy: 0.6431 - val_loss: 0.9055 - val_accuracy: 0.6450\n","Epoch 44/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8725 - accuracy: 0.6372\n","Epoch 44: accuracy did not improve from 0.64875\n","\n","Epoch 44: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 362s 7s/step - loss: 0.8725 - accuracy: 0.6372 - val_loss: 0.9407 - val_accuracy: 0.6275\n","Epoch 45/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8654 - accuracy: 0.6438\n","Epoch 45: accuracy did not improve from 0.64875\n","\n","Epoch 45: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 360s 7s/step - loss: 0.8654 - accuracy: 0.6438 - val_loss: 0.8905 - val_accuracy: 0.6300\n","Epoch 46/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.6272\n","Epoch 46: accuracy did not improve from 0.64875\n","\n","Epoch 46: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8774 - accuracy: 0.6272 - val_loss: 0.9444 - val_accuracy: 0.6150\n","Epoch 47/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8733 - accuracy: 0.6356\n","Epoch 47: accuracy did not improve from 0.64875\n","\n","Epoch 47: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.8733 - accuracy: 0.6356 - val_loss: 0.9195 - val_accuracy: 0.6175\n","Epoch 48/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8538 - accuracy: 0.6413\n","Epoch 48: accuracy did not improve from 0.64875\n","\n","Epoch 48: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.8538 - accuracy: 0.6413 - val_loss: 0.9542 - val_accuracy: 0.5800\n","Epoch 49/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8780 - accuracy: 0.6316\n","Epoch 49: accuracy did not improve from 0.64875\n","\n","Epoch 49: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 363s 7s/step - loss: 0.8780 - accuracy: 0.6316 - val_loss: 0.9146 - val_accuracy: 0.6075\n","Epoch 50/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8510 - accuracy: 0.6475\n","Epoch 50: accuracy did not improve from 0.64875\n","\n","Epoch 50: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.8510 - accuracy: 0.6475 - val_loss: 0.9869 - val_accuracy: 0.6125\n","Epoch 51/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.6394\n","Epoch 51: accuracy did not improve from 0.64875\n","\n","Epoch 51: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8623 - accuracy: 0.6394 - val_loss: 0.8966 - val_accuracy: 0.6150\n","Epoch 52/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8397 - accuracy: 0.6525\n","Epoch 52: accuracy improved from 0.64875 to 0.65250, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 52: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.8397 - accuracy: 0.6525 - val_loss: 0.8973 - val_accuracy: 0.6225\n","Epoch 53/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.6506\n","Epoch 53: accuracy did not improve from 0.65250\n","\n","Epoch 53: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 359s 7s/step - loss: 0.8415 - accuracy: 0.6506 - val_loss: 0.9637 - val_accuracy: 0.6125\n","Epoch 54/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8511 - accuracy: 0.6506\n","Epoch 54: accuracy did not improve from 0.65250\n","\n","Epoch 54: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 359s 7s/step - loss: 0.8511 - accuracy: 0.6506 - val_loss: 0.9389 - val_accuracy: 0.6375\n","Epoch 55/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8521 - accuracy: 0.6494\n","Epoch 55: accuracy did not improve from 0.65250\n","\n","Epoch 55: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8521 - accuracy: 0.6494 - val_loss: 0.9316 - val_accuracy: 0.6175\n","Epoch 56/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8443 - accuracy: 0.6497\n","Epoch 56: accuracy did not improve from 0.65250\n","\n","Epoch 56: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 357s 7s/step - loss: 0.8443 - accuracy: 0.6497 - val_loss: 0.9305 - val_accuracy: 0.5950\n","Epoch 57/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.6569\n","Epoch 57: accuracy improved from 0.65250 to 0.65688, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 57: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.8433 - accuracy: 0.6569 - val_loss: 0.9346 - val_accuracy: 0.6275\n","Epoch 58/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8462 - accuracy: 0.6569\n","Epoch 58: accuracy did not improve from 0.65688\n","\n","Epoch 58: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 361s 7s/step - loss: 0.8462 - accuracy: 0.6569 - val_loss: 0.9255 - val_accuracy: 0.6350\n","Epoch 59/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.6513\n","Epoch 59: accuracy did not improve from 0.65688\n","\n","Epoch 59: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8303 - accuracy: 0.6513 - val_loss: 0.9555 - val_accuracy: 0.6200\n","Epoch 60/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8443 - accuracy: 0.6409\n","Epoch 60: accuracy did not improve from 0.65688\n","\n","Epoch 60: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 358s 7s/step - loss: 0.8443 - accuracy: 0.6409 - val_loss: 0.8958 - val_accuracy: 0.6275\n","Epoch 61/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8323 - accuracy: 0.6484\n","Epoch 61: accuracy did not improve from 0.65688\n","\n","Epoch 61: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 360s 7s/step - loss: 0.8323 - accuracy: 0.6484 - val_loss: 0.9055 - val_accuracy: 0.6400\n","Epoch 62/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8410 - accuracy: 0.6484\n","Epoch 62: accuracy did not improve from 0.65688\n","\n","Epoch 62: val_accuracy did not improve from 0.64500\n","50/50 [==============================] - 360s 7s/step - loss: 0.8410 - accuracy: 0.6484 - val_loss: 0.9185 - val_accuracy: 0.6250\n","Epoch 63/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8487 - accuracy: 0.6538\n","Epoch 63: accuracy did not improve from 0.65688\n","\n","Epoch 63: val_accuracy improved from 0.64500 to 0.65250, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 365s 7s/step - loss: 0.8487 - accuracy: 0.6538 - val_loss: 0.9132 - val_accuracy: 0.6525\n","Epoch 64/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.6538\n","Epoch 64: accuracy did not improve from 0.65688\n","\n","Epoch 64: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 361s 7s/step - loss: 0.8223 - accuracy: 0.6538 - val_loss: 0.8889 - val_accuracy: 0.6375\n","Epoch 65/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8173 - accuracy: 0.6697\n","Epoch 65: accuracy improved from 0.65688 to 0.66969, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 65: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 360s 7s/step - loss: 0.8173 - accuracy: 0.6697 - val_loss: 0.8763 - val_accuracy: 0.6350\n","Epoch 66/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8323 - accuracy: 0.6572\n","Epoch 66: accuracy did not improve from 0.66969\n","\n","Epoch 66: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8323 - accuracy: 0.6572 - val_loss: 0.8934 - val_accuracy: 0.6300\n","Epoch 67/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8277 - accuracy: 0.6494\n","Epoch 67: accuracy did not improve from 0.66969\n","\n","Epoch 67: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 359s 7s/step - loss: 0.8277 - accuracy: 0.6494 - val_loss: 0.8984 - val_accuracy: 0.6300\n","Epoch 68/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8150 - accuracy: 0.6591\n","Epoch 68: accuracy did not improve from 0.66969\n","\n","Epoch 68: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 359s 7s/step - loss: 0.8150 - accuracy: 0.6591 - val_loss: 0.8554 - val_accuracy: 0.6250\n","Epoch 69/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8205 - accuracy: 0.6516\n","Epoch 69: accuracy did not improve from 0.66969\n","\n","Epoch 69: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8205 - accuracy: 0.6516 - val_loss: 0.9248 - val_accuracy: 0.6025\n","Epoch 70/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.6428\n","Epoch 70: accuracy did not improve from 0.66969\n","\n","Epoch 70: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8471 - accuracy: 0.6428 - val_loss: 0.9044 - val_accuracy: 0.6450\n","Epoch 71/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8222 - accuracy: 0.6631\n","Epoch 71: accuracy did not improve from 0.66969\n","\n","Epoch 71: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8222 - accuracy: 0.6631 - val_loss: 0.8723 - val_accuracy: 0.6400\n","Epoch 72/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8280 - accuracy: 0.6456\n","Epoch 72: accuracy did not improve from 0.66969\n","\n","Epoch 72: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 361s 7s/step - loss: 0.8280 - accuracy: 0.6456 - val_loss: 0.8986 - val_accuracy: 0.6350\n","Epoch 73/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8116 - accuracy: 0.6606\n","Epoch 73: accuracy did not improve from 0.66969\n","\n","Epoch 73: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 362s 7s/step - loss: 0.8116 - accuracy: 0.6606 - val_loss: 1.0858 - val_accuracy: 0.5775\n","Epoch 74/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8306 - accuracy: 0.6616\n","Epoch 74: accuracy did not improve from 0.66969\n","\n","Epoch 74: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 360s 7s/step - loss: 0.8306 - accuracy: 0.6616 - val_loss: 0.9347 - val_accuracy: 0.6075\n","Epoch 75/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.6759\n","Epoch 75: accuracy improved from 0.66969 to 0.67594, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 75: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 384s 8s/step - loss: 0.7904 - accuracy: 0.6759 - val_loss: 0.9174 - val_accuracy: 0.6275\n","Epoch 76/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8213 - accuracy: 0.6506\n","Epoch 76: accuracy did not improve from 0.67594\n","\n","Epoch 76: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 361s 7s/step - loss: 0.8213 - accuracy: 0.6506 - val_loss: 0.9458 - val_accuracy: 0.6025\n","Epoch 77/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.6700\n","Epoch 77: accuracy did not improve from 0.67594\n","\n","Epoch 77: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 361s 7s/step - loss: 0.8050 - accuracy: 0.6700 - val_loss: 0.9082 - val_accuracy: 0.6200\n","Epoch 78/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8320 - accuracy: 0.6516\n","Epoch 78: accuracy did not improve from 0.67594\n","\n","Epoch 78: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8320 - accuracy: 0.6516 - val_loss: 0.9224 - val_accuracy: 0.6325\n","Epoch 79/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8025 - accuracy: 0.6644\n","Epoch 79: accuracy did not improve from 0.67594\n","\n","Epoch 79: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 356s 7s/step - loss: 0.8025 - accuracy: 0.6644 - val_loss: 0.9140 - val_accuracy: 0.6325\n","Epoch 80/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8000 - accuracy: 0.6700\n","Epoch 80: accuracy did not improve from 0.67594\n","\n","Epoch 80: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8000 - accuracy: 0.6700 - val_loss: 0.9240 - val_accuracy: 0.6275\n","Epoch 81/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8060 - accuracy: 0.6675\n","Epoch 81: accuracy did not improve from 0.67594\n","\n","Epoch 81: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 358s 7s/step - loss: 0.8060 - accuracy: 0.6675 - val_loss: 0.8554 - val_accuracy: 0.6450\n","Epoch 82/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.6762\n","Epoch 82: accuracy improved from 0.67594 to 0.67625, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 82: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 362s 7s/step - loss: 0.7918 - accuracy: 0.6762 - val_loss: 0.8534 - val_accuracy: 0.6125\n","Epoch 83/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.6650\n","Epoch 83: accuracy did not improve from 0.67625\n","\n","Epoch 83: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 359s 7s/step - loss: 0.7997 - accuracy: 0.6650 - val_loss: 0.8923 - val_accuracy: 0.6225\n","Epoch 84/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.6722\n","Epoch 84: accuracy did not improve from 0.67625\n","\n","Epoch 84: val_accuracy did not improve from 0.65250\n","50/50 [==============================] - 359s 7s/step - loss: 0.7974 - accuracy: 0.6722 - val_loss: 0.8777 - val_accuracy: 0.6375\n","Epoch 85/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8081 - accuracy: 0.6716\n","Epoch 85: accuracy did not improve from 0.67625\n","\n","Epoch 85: val_accuracy improved from 0.65250 to 0.65750, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 361s 7s/step - loss: 0.8081 - accuracy: 0.6716 - val_loss: 0.8911 - val_accuracy: 0.6575\n","Epoch 86/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7746 - accuracy: 0.6778\n","Epoch 86: accuracy improved from 0.67625 to 0.67781, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 86: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7746 - accuracy: 0.6778 - val_loss: 0.9191 - val_accuracy: 0.6325\n","Epoch 87/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8082 - accuracy: 0.6675\n","Epoch 87: accuracy did not improve from 0.67781\n","\n","Epoch 87: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 357s 7s/step - loss: 0.8082 - accuracy: 0.6675 - val_loss: 0.9017 - val_accuracy: 0.6300\n","Epoch 88/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8039 - accuracy: 0.6528\n","Epoch 88: accuracy did not improve from 0.67781\n","\n","Epoch 88: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 360s 7s/step - loss: 0.8039 - accuracy: 0.6528 - val_loss: 0.8664 - val_accuracy: 0.6550\n","Epoch 89/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8056 - accuracy: 0.6681\n","Epoch 89: accuracy did not improve from 0.67781\n","\n","Epoch 89: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.8056 - accuracy: 0.6681 - val_loss: 0.8794 - val_accuracy: 0.6350\n","Epoch 90/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.6750\n","Epoch 90: accuracy did not improve from 0.67781\n","\n","Epoch 90: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 359s 7s/step - loss: 0.7949 - accuracy: 0.6750 - val_loss: 0.9463 - val_accuracy: 0.6175\n","Epoch 91/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7937 - accuracy: 0.6703\n","Epoch 91: accuracy did not improve from 0.67781\n","\n","Epoch 91: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 360s 7s/step - loss: 0.7937 - accuracy: 0.6703 - val_loss: 0.8973 - val_accuracy: 0.6075\n","Epoch 92/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.6697\n","Epoch 92: accuracy did not improve from 0.67781\n","\n","Epoch 92: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 362s 7s/step - loss: 0.7916 - accuracy: 0.6697 - val_loss: 0.8794 - val_accuracy: 0.6325\n","Epoch 93/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8163 - accuracy: 0.6572\n","Epoch 93: accuracy did not improve from 0.67781\n","\n","Epoch 93: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 360s 7s/step - loss: 0.8163 - accuracy: 0.6572 - val_loss: 0.9235 - val_accuracy: 0.6225\n","Epoch 94/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7772 - accuracy: 0.6759\n","Epoch 94: accuracy did not improve from 0.67781\n","\n","Epoch 94: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 359s 7s/step - loss: 0.7772 - accuracy: 0.6759 - val_loss: 0.8715 - val_accuracy: 0.6525\n","Epoch 95/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7802 - accuracy: 0.6784\n","Epoch 95: accuracy improved from 0.67781 to 0.67844, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 95: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 360s 7s/step - loss: 0.7802 - accuracy: 0.6784 - val_loss: 0.8704 - val_accuracy: 0.6550\n","Epoch 96/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8066 - accuracy: 0.6609\n","Epoch 96: accuracy did not improve from 0.67844\n","\n","Epoch 96: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 356s 7s/step - loss: 0.8066 - accuracy: 0.6609 - val_loss: 0.8821 - val_accuracy: 0.6375\n","Epoch 97/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7846 - accuracy: 0.6778\n","Epoch 97: accuracy did not improve from 0.67844\n","\n","Epoch 97: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7846 - accuracy: 0.6778 - val_loss: 0.8709 - val_accuracy: 0.6525\n","Epoch 98/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7887 - accuracy: 0.6697\n","Epoch 98: accuracy did not improve from 0.67844\n","\n","Epoch 98: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 359s 7s/step - loss: 0.7887 - accuracy: 0.6697 - val_loss: 0.8816 - val_accuracy: 0.6025\n","Epoch 99/200\n","50/50 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.6569\n","Epoch 99: accuracy did not improve from 0.67844\n","\n","Epoch 99: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 371s 7s/step - loss: 0.8121 - accuracy: 0.6569 - val_loss: 0.8751 - val_accuracy: 0.6350\n","Epoch 100/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7945 - accuracy: 0.6631\n","Epoch 100: accuracy did not improve from 0.67844\n","\n","Epoch 100: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 389s 8s/step - loss: 0.7945 - accuracy: 0.6631 - val_loss: 0.8836 - val_accuracy: 0.6300\n","Epoch 101/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.6916\n","Epoch 101: accuracy improved from 0.67844 to 0.69156, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 101: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 367s 7s/step - loss: 0.7683 - accuracy: 0.6916 - val_loss: 0.8713 - val_accuracy: 0.6450\n","Epoch 102/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7693 - accuracy: 0.6772\n","Epoch 102: accuracy did not improve from 0.69156\n","\n","Epoch 102: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 362s 7s/step - loss: 0.7693 - accuracy: 0.6772 - val_loss: 0.8639 - val_accuracy: 0.6375\n","Epoch 103/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7821 - accuracy: 0.6619\n","Epoch 103: accuracy did not improve from 0.69156\n","\n","Epoch 103: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 359s 7s/step - loss: 0.7821 - accuracy: 0.6619 - val_loss: 0.8897 - val_accuracy: 0.6150\n","Epoch 104/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7902 - accuracy: 0.6659\n","Epoch 104: accuracy did not improve from 0.69156\n","\n","Epoch 104: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7902 - accuracy: 0.6659 - val_loss: 0.8631 - val_accuracy: 0.6400\n","Epoch 105/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.6913\n","Epoch 105: accuracy did not improve from 0.69156\n","\n","Epoch 105: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 361s 7s/step - loss: 0.7618 - accuracy: 0.6913 - val_loss: 0.8576 - val_accuracy: 0.6375\n","Epoch 106/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.6806\n","Epoch 106: accuracy did not improve from 0.69156\n","\n","Epoch 106: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 357s 7s/step - loss: 0.7731 - accuracy: 0.6806 - val_loss: 0.8831 - val_accuracy: 0.6475\n","Epoch 107/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7805 - accuracy: 0.6719\n","Epoch 107: accuracy did not improve from 0.69156\n","\n","Epoch 107: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7805 - accuracy: 0.6719 - val_loss: 0.8889 - val_accuracy: 0.6475\n","Epoch 108/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7788 - accuracy: 0.6778\n","Epoch 108: accuracy did not improve from 0.69156\n","\n","Epoch 108: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 359s 7s/step - loss: 0.7788 - accuracy: 0.6778 - val_loss: 0.9010 - val_accuracy: 0.6425\n","Epoch 109/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7602 - accuracy: 0.6881\n","Epoch 109: accuracy did not improve from 0.69156\n","\n","Epoch 109: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7602 - accuracy: 0.6881 - val_loss: 0.8723 - val_accuracy: 0.6525\n","Epoch 110/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7639 - accuracy: 0.6784\n","Epoch 110: accuracy did not improve from 0.69156\n","\n","Epoch 110: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 357s 7s/step - loss: 0.7639 - accuracy: 0.6784 - val_loss: 0.8909 - val_accuracy: 0.6325\n","Epoch 111/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.6866\n","Epoch 111: accuracy did not improve from 0.69156\n","\n","Epoch 111: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 359s 7s/step - loss: 0.7647 - accuracy: 0.6866 - val_loss: 0.8730 - val_accuracy: 0.6225\n","Epoch 112/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.6762\n","Epoch 112: accuracy did not improve from 0.69156\n","\n","Epoch 112: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 360s 7s/step - loss: 0.7783 - accuracy: 0.6762 - val_loss: 0.8985 - val_accuracy: 0.6275\n","Epoch 113/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7499 - accuracy: 0.6988\n","Epoch 113: accuracy improved from 0.69156 to 0.69875, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 113: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 360s 7s/step - loss: 0.7499 - accuracy: 0.6988 - val_loss: 0.8632 - val_accuracy: 0.6425\n","Epoch 114/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7706 - accuracy: 0.6844\n","Epoch 114: accuracy did not improve from 0.69875\n","\n","Epoch 114: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 357s 7s/step - loss: 0.7706 - accuracy: 0.6844 - val_loss: 0.9162 - val_accuracy: 0.6350\n","Epoch 115/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7747 - accuracy: 0.6784\n","Epoch 115: accuracy did not improve from 0.69875\n","\n","Epoch 115: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 361s 7s/step - loss: 0.7747 - accuracy: 0.6784 - val_loss: 0.8512 - val_accuracy: 0.6525\n","Epoch 116/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7751 - accuracy: 0.6850\n","Epoch 116: accuracy did not improve from 0.69875\n","\n","Epoch 116: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 361s 7s/step - loss: 0.7751 - accuracy: 0.6850 - val_loss: 0.9108 - val_accuracy: 0.6275\n","Epoch 117/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7706 - accuracy: 0.6778\n","Epoch 117: accuracy did not improve from 0.69875\n","\n","Epoch 117: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7706 - accuracy: 0.6778 - val_loss: 0.8552 - val_accuracy: 0.6350\n","Epoch 118/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.6947\n","Epoch 118: accuracy did not improve from 0.69875\n","\n","Epoch 118: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7505 - accuracy: 0.6947 - val_loss: 0.8951 - val_accuracy: 0.6200\n","Epoch 119/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7790 - accuracy: 0.6816\n","Epoch 119: accuracy did not improve from 0.69875\n","\n","Epoch 119: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 357s 7s/step - loss: 0.7790 - accuracy: 0.6816 - val_loss: 0.8609 - val_accuracy: 0.6525\n","Epoch 120/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.6844\n","Epoch 120: accuracy did not improve from 0.69875\n","\n","Epoch 120: val_accuracy did not improve from 0.65750\n","50/50 [==============================] - 358s 7s/step - loss: 0.7668 - accuracy: 0.6844 - val_loss: 0.8557 - val_accuracy: 0.6525\n","Epoch 121/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7437 - accuracy: 0.6934\n","Epoch 121: accuracy did not improve from 0.69875\n","\n","Epoch 121: val_accuracy improved from 0.65750 to 0.66250, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 359s 7s/step - loss: 0.7437 - accuracy: 0.6934 - val_loss: 0.8468 - val_accuracy: 0.6625\n","Epoch 122/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.6844\n","Epoch 122: accuracy did not improve from 0.69875\n","\n","Epoch 122: val_accuracy did not improve from 0.66250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7726 - accuracy: 0.6844 - val_loss: 0.8674 - val_accuracy: 0.6450\n","Epoch 123/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7699 - accuracy: 0.6862\n","Epoch 123: accuracy did not improve from 0.69875\n","\n","Epoch 123: val_accuracy improved from 0.66250 to 0.67250, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 359s 7s/step - loss: 0.7699 - accuracy: 0.6862 - val_loss: 0.8472 - val_accuracy: 0.6725\n","Epoch 124/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.6869\n","Epoch 124: accuracy did not improve from 0.69875\n","\n","Epoch 124: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7633 - accuracy: 0.6869 - val_loss: 0.8496 - val_accuracy: 0.6450\n","Epoch 125/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7587 - accuracy: 0.6778\n","Epoch 125: accuracy did not improve from 0.69875\n","\n","Epoch 125: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 360s 7s/step - loss: 0.7587 - accuracy: 0.6778 - val_loss: 0.8928 - val_accuracy: 0.6325\n","Epoch 126/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.6753\n","Epoch 126: accuracy did not improve from 0.69875\n","\n","Epoch 126: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7626 - accuracy: 0.6753 - val_loss: 0.9019 - val_accuracy: 0.6575\n","Epoch 127/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7571 - accuracy: 0.6856\n","Epoch 127: accuracy did not improve from 0.69875\n","\n","Epoch 127: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7571 - accuracy: 0.6856 - val_loss: 0.8509 - val_accuracy: 0.6600\n","Epoch 128/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7598 - accuracy: 0.6869\n","Epoch 128: accuracy did not improve from 0.69875\n","\n","Epoch 128: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7598 - accuracy: 0.6869 - val_loss: 0.8919 - val_accuracy: 0.6350\n","Epoch 129/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7528 - accuracy: 0.6950\n","Epoch 129: accuracy did not improve from 0.69875\n","\n","Epoch 129: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7528 - accuracy: 0.6950 - val_loss: 0.8657 - val_accuracy: 0.6450\n","Epoch 130/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.6869\n","Epoch 130: accuracy did not improve from 0.69875\n","\n","Epoch 130: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7476 - accuracy: 0.6869 - val_loss: 0.8650 - val_accuracy: 0.6325\n","Epoch 131/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.6922\n","Epoch 131: accuracy did not improve from 0.69875\n","\n","Epoch 131: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7513 - accuracy: 0.6922 - val_loss: 0.9124 - val_accuracy: 0.6300\n","Epoch 132/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7488 - accuracy: 0.6913\n","Epoch 132: accuracy did not improve from 0.69875\n","\n","Epoch 132: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7488 - accuracy: 0.6913 - val_loss: 0.9049 - val_accuracy: 0.6225\n","Epoch 133/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7482 - accuracy: 0.6866\n","Epoch 133: accuracy did not improve from 0.69875\n","\n","Epoch 133: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7482 - accuracy: 0.6866 - val_loss: 0.8683 - val_accuracy: 0.6575\n","Epoch 134/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.6875\n","Epoch 134: accuracy did not improve from 0.69875\n","\n","Epoch 134: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7491 - accuracy: 0.6875 - val_loss: 0.8555 - val_accuracy: 0.6550\n","Epoch 135/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.6856\n","Epoch 135: accuracy did not improve from 0.69875\n","\n","Epoch 135: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 359s 7s/step - loss: 0.7533 - accuracy: 0.6856 - val_loss: 0.8421 - val_accuracy: 0.6725\n","Epoch 136/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7430 - accuracy: 0.6938\n","Epoch 136: accuracy did not improve from 0.69875\n","\n","Epoch 136: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7430 - accuracy: 0.6938 - val_loss: 0.8827 - val_accuracy: 0.6275\n","Epoch 137/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7623 - accuracy: 0.6787\n","Epoch 137: accuracy did not improve from 0.69875\n","\n","Epoch 137: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7623 - accuracy: 0.6787 - val_loss: 0.8504 - val_accuracy: 0.6500\n","Epoch 138/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7737 - accuracy: 0.6778\n","Epoch 138: accuracy did not improve from 0.69875\n","\n","Epoch 138: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7737 - accuracy: 0.6778 - val_loss: 0.9091 - val_accuracy: 0.6450\n","Epoch 139/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7400 - accuracy: 0.7000\n","Epoch 139: accuracy improved from 0.69875 to 0.70000, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 139: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7400 - accuracy: 0.7000 - val_loss: 0.8436 - val_accuracy: 0.6500\n","Epoch 140/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.6881\n","Epoch 140: accuracy did not improve from 0.70000\n","\n","Epoch 140: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7460 - accuracy: 0.6881 - val_loss: 0.8993 - val_accuracy: 0.6225\n","Epoch 141/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7523 - accuracy: 0.6903\n","Epoch 141: accuracy did not improve from 0.70000\n","\n","Epoch 141: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7523 - accuracy: 0.6903 - val_loss: 0.8433 - val_accuracy: 0.6600\n","Epoch 142/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7361 - accuracy: 0.7050\n","Epoch 142: accuracy improved from 0.70000 to 0.70500, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 142: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7361 - accuracy: 0.7050 - val_loss: 0.8654 - val_accuracy: 0.6350\n","Epoch 143/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.6978\n","Epoch 143: accuracy did not improve from 0.70500\n","\n","Epoch 143: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7375 - accuracy: 0.6978 - val_loss: 0.8637 - val_accuracy: 0.6375\n","Epoch 144/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7496 - accuracy: 0.6934\n","Epoch 144: accuracy did not improve from 0.70500\n","\n","Epoch 144: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7496 - accuracy: 0.6934 - val_loss: 0.8844 - val_accuracy: 0.6400\n","Epoch 145/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.6963\n","Epoch 145: accuracy did not improve from 0.70500\n","\n","Epoch 145: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 360s 7s/step - loss: 0.7393 - accuracy: 0.6963 - val_loss: 0.8706 - val_accuracy: 0.6525\n","Epoch 146/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.6963\n","Epoch 146: accuracy did not improve from 0.70500\n","\n","Epoch 146: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7483 - accuracy: 0.6963 - val_loss: 0.9098 - val_accuracy: 0.6400\n","Epoch 147/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.6772\n","Epoch 147: accuracy did not improve from 0.70500\n","\n","Epoch 147: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7480 - accuracy: 0.6772 - val_loss: 0.8461 - val_accuracy: 0.6500\n","Epoch 148/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.6934\n","Epoch 148: accuracy did not improve from 0.70500\n","\n","Epoch 148: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7487 - accuracy: 0.6934 - val_loss: 0.8803 - val_accuracy: 0.6525\n","Epoch 149/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7284 - accuracy: 0.6969\n","Epoch 149: accuracy did not improve from 0.70500\n","\n","Epoch 149: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7284 - accuracy: 0.6969 - val_loss: 0.8401 - val_accuracy: 0.6675\n","Epoch 150/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.6978\n","Epoch 150: accuracy did not improve from 0.70500\n","\n","Epoch 150: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7369 - accuracy: 0.6978 - val_loss: 0.8796 - val_accuracy: 0.6500\n","Epoch 151/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.6928\n","Epoch 151: accuracy did not improve from 0.70500\n","\n","Epoch 151: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7317 - accuracy: 0.6928 - val_loss: 0.8708 - val_accuracy: 0.6500\n","Epoch 152/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.7038\n","Epoch 152: accuracy did not improve from 0.70500\n","\n","Epoch 152: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7256 - accuracy: 0.7038 - val_loss: 0.8414 - val_accuracy: 0.6600\n","Epoch 153/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.6916\n","Epoch 153: accuracy did not improve from 0.70500\n","\n","Epoch 153: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7348 - accuracy: 0.6916 - val_loss: 0.8725 - val_accuracy: 0.6500\n","Epoch 154/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.7069\n","Epoch 154: accuracy improved from 0.70500 to 0.70688, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 154: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7153 - accuracy: 0.7069 - val_loss: 0.8769 - val_accuracy: 0.6375\n","Epoch 155/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7380 - accuracy: 0.6909\n","Epoch 155: accuracy did not improve from 0.70688\n","\n","Epoch 155: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7380 - accuracy: 0.6909 - val_loss: 0.8488 - val_accuracy: 0.6675\n","Epoch 156/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7560 - accuracy: 0.6816\n","Epoch 156: accuracy did not improve from 0.70688\n","\n","Epoch 156: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 358s 7s/step - loss: 0.7560 - accuracy: 0.6816 - val_loss: 0.8612 - val_accuracy: 0.6650\n","Epoch 157/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7349 - accuracy: 0.6988\n","Epoch 157: accuracy did not improve from 0.70688\n","\n","Epoch 157: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7349 - accuracy: 0.6988 - val_loss: 0.8271 - val_accuracy: 0.6575\n","Epoch 158/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.6941\n","Epoch 158: accuracy did not improve from 0.70688\n","\n","Epoch 158: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7357 - accuracy: 0.6941 - val_loss: 0.8260 - val_accuracy: 0.6725\n","Epoch 159/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.7125\n","Epoch 159: accuracy improved from 0.70688 to 0.71250, saving model to /Users/bened/Python/Farmku/Rice\\acc_best_model_2.hdf5\n","\n","Epoch 159: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7143 - accuracy: 0.7125 - val_loss: 0.8934 - val_accuracy: 0.6450\n","Epoch 160/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.7000\n","Epoch 160: accuracy did not improve from 0.71250\n","\n","Epoch 160: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 355s 7s/step - loss: 0.7348 - accuracy: 0.7000 - val_loss: 0.8447 - val_accuracy: 0.6625\n","Epoch 161/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.6991\n","Epoch 161: accuracy did not improve from 0.71250\n","\n","Epoch 161: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7245 - accuracy: 0.6991 - val_loss: 0.8500 - val_accuracy: 0.6575\n","Epoch 162/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.6950\n","Epoch 162: accuracy did not improve from 0.71250\n","\n","Epoch 162: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 355s 7s/step - loss: 0.7387 - accuracy: 0.6950 - val_loss: 0.9281 - val_accuracy: 0.6275\n","Epoch 163/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.7081\n","Epoch 163: accuracy did not improve from 0.71250\n","\n","Epoch 163: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7193 - accuracy: 0.7081 - val_loss: 0.8488 - val_accuracy: 0.6375\n","Epoch 164/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.6988\n","Epoch 164: accuracy did not improve from 0.71250\n","\n","Epoch 164: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 355s 7s/step - loss: 0.7304 - accuracy: 0.6988 - val_loss: 0.9112 - val_accuracy: 0.6150\n","Epoch 165/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7168 - accuracy: 0.7056\n","Epoch 165: accuracy did not improve from 0.71250\n","\n","Epoch 165: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7168 - accuracy: 0.7056 - val_loss: 0.8750 - val_accuracy: 0.6275\n","Epoch 166/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7364 - accuracy: 0.7006\n","Epoch 166: accuracy did not improve from 0.71250\n","\n","Epoch 166: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 357s 7s/step - loss: 0.7364 - accuracy: 0.7006 - val_loss: 0.8373 - val_accuracy: 0.6600\n","Epoch 167/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.7044\n","Epoch 167: accuracy did not improve from 0.71250\n","\n","Epoch 167: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 354s 7s/step - loss: 0.7378 - accuracy: 0.7044 - val_loss: 0.8184 - val_accuracy: 0.6500\n","Epoch 168/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7167 - accuracy: 0.7013\n","Epoch 168: accuracy did not improve from 0.71250\n","\n","Epoch 168: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 355s 7s/step - loss: 0.7167 - accuracy: 0.7013 - val_loss: 0.8560 - val_accuracy: 0.6525\n","Epoch 169/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7275 - accuracy: 0.7100\n","Epoch 169: accuracy did not improve from 0.71250\n","\n","Epoch 169: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7275 - accuracy: 0.7100 - val_loss: 0.8296 - val_accuracy: 0.6625\n","Epoch 170/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7254 - accuracy: 0.7022\n","Epoch 170: accuracy did not improve from 0.71250\n","\n","Epoch 170: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7254 - accuracy: 0.7022 - val_loss: 0.8475 - val_accuracy: 0.6400\n","Epoch 171/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.7100\n","Epoch 171: accuracy did not improve from 0.71250\n","\n","Epoch 171: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 355s 7s/step - loss: 0.7171 - accuracy: 0.7100 - val_loss: 0.8682 - val_accuracy: 0.6575\n","Epoch 172/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.6994\n","Epoch 172: accuracy did not improve from 0.71250\n","\n","Epoch 172: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 354s 7s/step - loss: 0.7328 - accuracy: 0.6994 - val_loss: 0.8451 - val_accuracy: 0.6325\n","Epoch 173/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7253 - accuracy: 0.7084\n","Epoch 173: accuracy did not improve from 0.71250\n","\n","Epoch 173: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 354s 7s/step - loss: 0.7253 - accuracy: 0.7084 - val_loss: 0.8302 - val_accuracy: 0.6650\n","Epoch 174/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7228 - accuracy: 0.6963\n","Epoch 174: accuracy did not improve from 0.71250\n","\n","Epoch 174: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 354s 7s/step - loss: 0.7228 - accuracy: 0.6963 - val_loss: 0.8393 - val_accuracy: 0.6300\n","Epoch 175/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7168 - accuracy: 0.7094\n","Epoch 175: accuracy did not improve from 0.71250\n","\n","Epoch 175: val_accuracy did not improve from 0.67250\n","50/50 [==============================] - 356s 7s/step - loss: 0.7168 - accuracy: 0.7094 - val_loss: 0.8780 - val_accuracy: 0.6400\n","Epoch 176/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7250 - accuracy: 0.7013\n","Epoch 176: accuracy did not improve from 0.71250\n","\n","Epoch 176: val_accuracy improved from 0.67250 to 0.67500, saving model to /Users/bened/Python/Farmku/Rice\\val_acc_best_model_2.hdf5\n","50/50 [==============================] - 356s 7s/step - loss: 0.7250 - accuracy: 0.7013 - val_loss: 0.8399 - val_accuracy: 0.6750\n","Epoch 177/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.6994\n","Epoch 177: accuracy did not improve from 0.71250\n","\n","Epoch 177: val_accuracy did not improve from 0.67500\n","50/50 [==============================] - 354s 7s/step - loss: 0.7266 - accuracy: 0.6994 - val_loss: 0.8307 - val_accuracy: 0.6625\n","Epoch 178/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7181 - accuracy: 0.7122\n","Epoch 178: accuracy did not improve from 0.71250\n","\n","Epoch 178: val_accuracy did not improve from 0.67500\n","50/50 [==============================] - 357s 7s/step - loss: 0.7181 - accuracy: 0.7122 - val_loss: 0.8719 - val_accuracy: 0.6425\n","Epoch 179/200\n","50/50 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.7084\n","Epoch 179: accuracy did not improve from 0.71250\n","\n","Epoch 179: val_accuracy did not improve from 0.67500\n","50/50 [==============================] - 356s 7s/step - loss: 0.7081 - accuracy: 0.7084 - val_loss: 0.8543 - val_accuracy: 0.6550\n","Epoch 180/200\n","28/50 [===============>..............] - ETA: 2:22 - loss: 0.7187 - accuracy: 0.7065"]}],"source":["history_2 = custom_model_2.fit(training_dataset,\n","                               validation_data = validation_dataset,\n","                               epochs = 200,\n","                               verbose = 1,\n","                               callbacks=[acc_checkpoint, val_acc_checkpoint, stopEpoch()])"]},{"cell_type":"code","source":["eval = custom_model_7.evaluate(testing_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLIMJ6PSUx4W","executionInfo":{"status":"ok","timestamp":1684823930264,"user_tz":-420,"elapsed":81659,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}},"outputId":"15cbfa05-4351-4900-bac4-8a4f1e6c6c7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 76s 8s/step - loss: 0.8930 - accuracy: 0.7000\n"]}]},{"cell_type":"code","source":["custom_model_7.save('/Users/bened/Python/Farmku/Rice/saved_model/my_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63hs1tCa1aQH","executionInfo":{"status":"ok","timestamp":1684816089135,"user_tz":-420,"elapsed":24236,"user":{"displayName":"Farm Ku","userId":"05904211216712481346"}},"outputId":"86f5278f-6315-4439-9110-a304e7617434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 95). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /Users/bened/Python/Farmku/Rice/saved_model/my_model\\assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /Users/bened/Python/Farmku/Rice/saved_model/my_model\\assets\n"]}]},{"cell_type":"code","source":["custom_model_7.save('/Users/bened/Python/Farmku/Rice/saved_model/latest_further_model.h5')"],"metadata":{"id":"AY9Q5Dqc2PhG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Saved Model"],"metadata":{"id":"lP-Rxf_X2TJN"}},{"cell_type":"code","source":["load_model = tf.keras.models.load_model('/Users/bened/Python/Farmku/Rice/acc_best_model_7_epoch191.hdf5')"],"metadata":{"id":"hU1RhNEP2YAI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZE4K2ZTH3o0A"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}